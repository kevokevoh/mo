{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7256d70-7dc7-4ecd-82a3-9ee0d7a540c6",
   "metadata": {},
   "source": [
    "# First Consideration\n",
    "Considering the various metrics available in the dataset:\n",
    "- How would you prioritize which metrics to analyze first to address user dissatisfaction with information access?\n",
    "- What insights would you be looking for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e39205cf-2bd6-467e-94df-37e91667e50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (3.1.5)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.14.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m255.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.26.0 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Cellar/jupyterlab/4.2.3/libexec/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading scipy-1.14.0-cp312-cp312-macosx_10_9_x86_64.whl (39.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.2/39.2 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.14.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/Cellar/jupyterlab/4.2.3/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas openpyxl scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27bccd79-6bec-469b-b516-8565ada12477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet names: ['Data']\n",
      "\n",
      "Column names in sheet 'Data':\n",
      "['Created Time', 'loanuuid', 'Contact Disposition', 'Service Request Status', 'Whatsapp Csat', 'Ease Of Contact', 'Overall Csat', 'Unsatisfied Components', 'Unsatisfied Services', 'Feedback Notes', 'Nps Score', 'Ces Score', 'Sale Process Csat', 'Delivery Process Csat', 'Product Csat', 'Ussd Csat', 'Old Csat X', 'Old Csat Y']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file from a directory with appropriate permissions\n",
    "file_path = './mo_csat.xlsx'\n",
    "# Load the Excel file\n",
    "excel_file = pd.ExcelFile(file_path)\n",
    "\n",
    "# Print the names of all sheets in the Excel file\n",
    "print(\"Sheet names:\", excel_file.sheet_names)\n",
    "\n",
    "# Iterate through each sheet and print the column names from the first row\n",
    "for sheet_name in excel_file.sheet_names:\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    print(f\"\\nColumn names in sheet '{sheet_name}':\")\n",
    "    print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c45267d-476a-47df-877a-9909c471a5fa",
   "metadata": {},
   "source": [
    "# Fields Available in the Customer Satisfaction Survey:**\n",
    "**Identifiers and Timestamps**:\n",
    "- Created Time: When the CSAT survey was created or submitted\n",
    "- loanuuid: Unique identifier for the loan, linking to the loan data\n",
    "\n",
    "**Survey Status**:\n",
    "- Contact Disposition: Outcome of the contact attempt\n",
    "- Service Request Status: Current status of the service request\n",
    "\n",
    "**Satisfaction Metrics**:\n",
    "- Whatsapp Csat: Satisfaction with WhatsApp communication\n",
    "- Ease Of Contact: How easy it was to contact the company\n",
    "- Overall Csat: Overall customer satisfaction\n",
    "- Nps Score: Net Promoter Score\n",
    "- Ces Score: Customer Effort Score\n",
    "\n",
    "**Process-specific Satisfaction**:\n",
    "- Sale Process Csat: Satisfaction with the sales process\n",
    "- Delivery Process Csat: Satisfaction with the delivery process\n",
    "- Product Csat: Satisfaction with the product itself\n",
    "- Ussd Csat: Satisfaction with USSD (Unstructured Supplementary Service Data) service\n",
    "\n",
    "**Feedback Details**:\n",
    "- Unsatisfied Components: Areas where the customer was not satisfied\n",
    "- Unsatisfied Services: Specific services that didn't meet expectations\n",
    "- Feedback Notes: Additional comments or feedback from the customer\n",
    "\n",
    "**Legacy or Alternative Metrics**:\n",
    "- Old Csat X and Old Csat Y: Possibly previous CSAT measurement systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9160f9b-a800-417c-b7ea-92e32dfbdbc8",
   "metadata": {},
   "source": [
    "Let's focus on analyzing user dissatisfaction with information access:\n",
    "We need to identify the relevant metrics:\n",
    "- Unsatisfied Components and Unsatisfied Services - What services and components are specified by users and whether acess to information is prioritised\n",
    "- Ease of Contact - Are users able to contact Mophones to access relevant information\n",
    "- Overal Csat - Taking this as a metric of overal usersatisfaction we can run quantitative analysis ie does ease of contact affect overal csat\n",
    "- Ces Score: Higher scores might indicate difficulty in accessing information.\n",
    "- Whatsapp Csat and Ussd Csat: These channels are often used for information access and can be used to know if a specific channel is having issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d1359b-f8dd-4b57-adf5-03b2816d7867",
   "metadata": {},
   "source": [
    "Low level Analytics\n",
    "- the percentage of users with No for Ease Of Contact.\n",
    "- Correlate Ease Of Contact scores with Overall Csat to see the impact.\n",
    "- Compare Ces Scores for users with No vs. Yes Ease Of Contact scores.\n",
    "- Analyze Whatsapp Csat and Ussd Csat in relation to Ease Of Contact.\n",
    "\n",
    "Segmentation- (There is a host of permutations that we can tabulate here looking for significance)\n",
    "- Group users by their Ease Of Contact and analyze characteristics of each group (loan amounts, repayment status, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9a312-b71a-4a97-a016-714637e48145",
   "metadata": {},
   "source": [
    "# how would you prioritize which metrics to analyze first to address user dissatisfaction with information access?\n",
    "Naturally the first step is to do a quick skim of the data to try and identify high level patterns to investigate further and also prior to the csat there are some assumptions that I hold and would like to validate/ invalidate. A quick assumption that i hold for example is that if users are able to contact mophones easily to obtain information then it would naturally improve their satisfaction with the company. Hence i'd seek to first validate this hypothesis:\n",
    "\n",
    "H_0: There is no significant association between the ease of contact and overall customer satisfaction.\n",
    "H_1: There is a significant association between the ease of contact and overall customer satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80f4a32-1a68-4d67-8292-a771e290428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contingency Table:\n",
      "Overall Csat     No  Yes\n",
      "Ease Of Contact         \n",
      "No               18   15\n",
      "Yes              19  204\n",
      "\n",
      "Chi-square statistic: 45.59781627955349\n",
      "p-value: 1.4520337090165093e-11\n",
      "\n",
      "Interpretation:\n",
      "There is a statistically significant association between Ease of Contact and Overall CSAT.\n",
      "\n",
      "Cramer's V: 0.422038469623334\n",
      "Moderate association\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "df = pd.read_excel('./mo_csat.xlsx')\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df['Ease Of Contact'], df['Overall Csat'])\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"\\nChi-square statistic: {chi2}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant association between Ease of Contact and Overall CSAT.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant association between Ease of Contact and Overall CSAT.\")\n",
    "# Calculate Cramer's V\n",
    "n = contingency_table.sum().sum()\n",
    "min_dim = min(contingency_table.shape) - 1\n",
    "cramer_v = np.sqrt(chi2 / (n * min_dim))\n",
    "\n",
    "print(f\"\\nCramer's V: {cramer_v}\")\n",
    "if cramer_v < 0.1:\n",
    "    print(\"Negligible association\")\n",
    "elif cramer_v < 0.3:\n",
    "    print(\"Weak association\")\n",
    "elif cramer_v < 0.5:\n",
    "    print(\"Moderate association\")\n",
    "else:\n",
    "    print(\"Strong association\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3065fd57-8aeb-4164-82ed-acb983890fd3",
   "metadata": {},
   "source": [
    "# Context\n",
    "The Chi-square statistic measures the discrepancy between the ease of contact and overall customer satisfaction in a contingency table. A larger Chi-square value indicates a greater difference between ease of contact and overall customer satisfaction, suggesting a stronger association between the variables.\n",
    "\n",
    "The p-value tells us the probability of obtaining a Chi-square statistic as extreme as, or more extreme than, the one observed, assuming that the null hypothesis is true. The null hypothesis typically states that there is no association between the two variables.\n",
    "\n",
    "Cramer's V is a measure of the strength of association between two nominal variables. It ranges from 0 to 1.\n",
    "\n",
    "## Summary\n",
    "Chi-square statistic (45.60) indicates a notable discrepancy between observed and expected frequencies.\n",
    "p-value (1.45e-11) indicates that the association is statistically significant.\n",
    "Cramer's V (0.422) indicates a moderate strength of association.\n",
    "\n",
    "## Hence we can invalidate the null hypothesis. This indicates that there is a statistically significant association between the ease of contact and overall customer satisfaction. Furthermore, a Cramer's V of 0.422 suggests that this association is of moderate strength, implying that ease of contact has a notable impact on overall customer satisfaction and hence the product should work to simplify user contact or reduce the need of user contact. This can now be a secondary investigation of why do the users feel the need to contact us. We can now explore the ces and maybe compare that to Unsatisfied Components and Unsatisfied Services to retrieve more insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e30c3f-15e2-4045-aba1-158f8497e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is just me playing around with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d790c1f3-919c-4f20-b0b3-efa01e69a17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Unsatisfied Components:\n",
      "All is ok                    144\n",
      "Battery                       70\n",
      "All is ok on PHOINE           55\n",
      "Network Issues                11\n",
      "Simtool kit                    9\n",
      "Charging Cable                 8\n",
      " All is ok                     7\n",
      "Screen                         6\n",
      "New Apps loading               6\n",
      "Phone Physical appearance      5\n",
      "Name: count, dtype: int64\n",
      "Top 10 Unsatisfied Services:\n",
      "All is OK               150\n",
      "All is OK on service     73\n",
      "Reaching support         32\n",
      "Phone un-locking         27\n",
      "Making payments          25\n",
      "Balance inquiries        20\n",
      " Phone un-locking        15\n",
      " Balance inquiries        9\n",
      " All is OK                7\n",
      " Making payments          6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unsatisfied_components = df['Unsatisfied Components'].str.split(',', expand=True).stack()\n",
    "unsatisfied_services = df['Unsatisfied Services'].str.split(',', expand=True).stack()\n",
    "top_unsatisfied_components = unsatisfied_components.value_counts().head(10)\n",
    "top_unsatisfied_services = unsatisfied_services.value_counts().head(10)\n",
    "print(\"Top 10 Unsatisfied Components:\")\n",
    "print(top_unsatisfied_components) # Needs a bit of clean-up\n",
    "print(\"Top 10 Unsatisfied Services:\")\n",
    "print(top_unsatisfied_services) # This supports our high level hypothesis because users complain reaching support is the top unsatisfied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f6f1ad3-7f3c-492f-b950-2756c593bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of feedback mentioning information access issues: 9.89%\n"
     ]
    }
   ],
   "source": [
    "def contains_info_access_issue(text):\n",
    "    keywords = ['alert', 'balance', 'battery', 'unlock', 'quality', 'network']\n",
    "    return any(keyword in str(text).lower() for keyword in keywords)\n",
    "info_access_issues = df['Feedback Notes'].apply(contains_info_access_issue).sum()\n",
    "total_feedback = len(df)\n",
    "print(f\"Proportion of feedback mentioning information access issues: {info_access_issues / total_feedback:.2%}\")\n",
    "#TODO: Can implement a word cloud to see what are the heat maps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd6375a-ef60-4b69-8e2b-b95b3e97a6d9",
   "metadata": {},
   "source": [
    "# What insights would i be looking for?\n",
    "- Trend Analysis - if the csat is part of a continuous effort to understand the consumers then we can evaluate trends on whether the product is improving in accordance to the consumers or not and also evaluate if previous efforts yielded the outcomes that were being persued\n",
    "- Correlations and their relative strengths - I would also be looking at corelations and their strengths to keep tuning future efforts to tasks and efforts that yield maximum user satisfaction.\n",
    "- Segmentation Analysis - Analyse if segments of users have prevailing behaviors that can influence the product decisions a high level would be are payment defaulters having more support issues due to problems activating the phones etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda74c5f-758b-459f-a037-ce4d8843bc18",
   "metadata": {},
   "source": [
    "# In the context of the MoPhones reality, what would you suggest are the three main product priorities and how would you capture these in OKRs including contributions?\n",
    "\n",
    "## Objective 1: Increase Sales by 30% MOM.\n",
    "### Key Results and Individual Contributions:\n",
    "    *Increase Conversion Rate*:\n",
    "        Contribution: Design, implement and test new features and improvements with the team in the sales pipeline supporting agents, merchants and direct sales to streamline the user onboarding process and reduce friction points. This include collaborations with the eng, design and ground teams to understand their pain points as well as invest in education and documentation of the product so that they are equiped to meet their sales targets.\n",
    "    *Enhance Targeting*:\n",
    "        Contribution: Implement trend and segmentation analytics to better segment and target potential customers and develop features to personalise experiences based on user behavior and data\n",
    "\n",
    "## Objective 2: Enhance Customer Service by making ease of contact to not be statistically significant to overal CSAT\n",
    "### Key Results and Individual Contributions:\n",
    "    *Improve Customer Satisfaction*:\n",
    "        Contribution: Identify user pain points through csats, feedback tools and dashboards and prioritize development efforts to address these issues.\n",
    "    *Increase Resolution Rate*:\n",
    "        Contribution: Interface with the customer service teams as well as agents to ascertain their needs and information required in order to facilitate faster issue resolution as well as tracking and monitoring resolution times and identifying bottlenecks for future iterations of improvements.\n",
    "\n",
    "## Objective 3: Improve Repayments and Customer Retention by improving churn rate by 15%\n",
    "### Key Results and Individual Contributions:\n",
    "    *Reduce Default Rate*:\n",
    "        Contribution: Develop algorithims to assess and mitigate customer default risks early as well as alert users of upcoming payments and offer assistance if requested by the user\n",
    "    *Implement Automatic Payments*:\n",
    "        Contribution: Implement and automate payments for active users ie mpesa scheduled payments(ratiba) as well as card payments to reduce the friction of users manually undertaking this task as well as encourage and facilitate enrolment in automatic payment plans."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
